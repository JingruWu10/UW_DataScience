# UW PCE Data Science Autumn 2017 Assignment 4
# Leo Salemann 10/27/17

# 1) Training vs. Test Data
1.a) Training data is used to create the model. The "model trainer" tries to get the best fit possible.

1.b) The two keys to selecting training data is to answer "how many?" and "which ones?" For "how many"", a typical answer is 20% to 30% of the population, unless the dataset is exteremely large. For "which ones"", the key is to make a random selection, so that the distribution of attribute values in your training set matches matches the population as a whole. If the data is ordered in some way, it may be important to randomize the ordering (or randomize your seleciton index) before proceeding.

1.c) Obtain model predictions from both datasets, and compute accuracy measures.  The dataset that yields the 
higher accuracy figures is probably the training dataset.




# 2) 300 indivudals; 149 with the cold; 151 healthy; 
100 tested; 
90 healthy; 85 predicted
10 ill;      7 predicted

Confusion Matrix (for predicting "is sick")

|  | ill | ok
|--|-----|----
|P |  7  |  5
|N |  3  | 85

See accompanying DS400_HW04.R for forumulae
2.a) Senstivty:    70 %
2.b) Specificity:  94 %
2.c) Accuracy:     92 %
2.d) Precision:    58 %
2.e) Recall:       70 %


# 3) ROC charts
3.a) The upper-right corner of the ROC graph (x=y=1, or TPR=FPR=100%) corresponds to a threshold of zero.
3.b) The origin of the ROC graph (x=y=0 OR TPR=FPR=%0 coresponds to a threshold of one)
3.c) There is no point on a genral ROC graph that always corresponds to a threshold of 0.5. 
     Different models & predictions will yield different ROC curves, which will have different values 
     for a threshold of 0.5
     
     
# 4) ROC chart with FPR=0.4, TPR=0.8, Accuracy 0.7, 1000 cases

4.a) Find the confusion matrix
Start with basic equations:
  Acc = (TP+TN)/(TP+FP+TN+FN)
  FPR = FP/(FP+TN)
  TPR = TP/(TP+FN)

Make some substitutions
  Acc = (TP+TN)/(TP+FP+TN+FN)
  0.7 = (TP+TN)/1000 #1000 cases
  700 = TP+TN
  
 1000 = TP+FP+TN+FN  #1000 cases
 1000 = 700 + FP + FN
  300 = FP + FN
  
  Get TN in terms of FP
            FPR = FP/(FP+TN)
            0.4 = FP/(FP+TN)
  0.4FP + 0.4TN = FP
          0.4TN = 0.6FP 
        (2/3)TN = FP
             TN = 1.5FP

 
 Get FN in terms of TP
            TPR = TP/(TP+FN)
            0.8 = TP/(TP+FN)
  0.8TP + 0.8FN = TP
          0.8FN = 0.2TP
             FN = 0.25TP
            4FN = TP 
            
Get TP in terms of TN
          700 = TP + TN
     700 - TN = TP    

            
Solve for TN
  300 =      FP +      FN
  300 = (2/3)TN + (1/4)TP
  300 = (2/3)TN + (1/4)(700-TN)
  300 = (2/3)TN + 175 - (1/4)TN
  125 = (5/12)TN
  300 = TN
  
Solve for TP
  700 = TP + TN
  700 = TP + 300
  400 = TP
  
Solve for FP
          FPR = FP/(FP+TN)
          0.4 = FP/(FP+300)
  0.4FP + 120 = FP
          120 = 0.6FP
          200 = FP
  
  
Solve for FN
 1000 = TP+FP+TN+FN 
 1000 = 400+200+300+FN
  100 = FN


Confusion Matrix  
|Pr| Yes | No
|--|-----|----
|P | TP  | FP 
|N | FN  | TN


Confusion Matrix  
|Pr| Yes | No
|--|-----|----
|P | 400 |200 
|N | 100 |300


4.b) Probability threshold cannot be determined.
The best we can do is say the ROC curve has a point at (FPR = 0.4, TPR = 0.8); 
but we can't say what the curve looks like on either side of this point 
(besides intersections at 0,0 and 1,1).
