{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything's Linear with the Right Kernel Function\n",
    "_Exploring high-dimensional space with Support Vector Machines_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Science 420 BB\n",
    "#### University of Washington Professional & Continuing Education\n",
    "#### Homework 5: Support Vector Machines\n",
    "#### Leo Salemann, 5/22/18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "**Explain the differences between traditional two-class Support Vector Machines (SMVs) versus two-class Locally-Deep Support Vector Machines (LD-SVMs). Provide examples of when you will prefer to use one over the other.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Class SVMs in General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both types of Support Vector Machines (SVMs, LD-SVMs) are designed to solve binary classification problems by finding a hyperplane that separates the input data into two classes. If the data is two-dimensional (only two features per observation), the hyperplane becomes a line; for three dimensional data it beocmes a regular 2D plane, and for N-dimensions (data with N features per observation) it beocmes an N-1 dimensional hyperplane. The key point here is that SVMs are _linear_ classifiers - meaning that the line mentioned for the 2D case the hyperplane is an actual straight line not a curve; for the 3D case it's a flat 2D plane not a wavy surface; and for higher dimensions the hyperplane is still \"flat\" in whatever sense that may mean in N-1 space. In cases where the data doesn't lend it self to classificaiton by a \"flat\" separate (i.e. most of the time) a _Kernel Function_ is employed to project the data into a higher dimensional space in which a \"flat\" separator works. \n",
    "\n",
    "Consider a random collection og pixels sampled from an image of a fried egg. We have [x, y, color] and want to clasify yolk (round, in the center)  vs. egg white (backgroud, everythere else). No straight line will separate our yolk from white, but if we project our dataset into 3D space, the yolk becomes a \"mountain\" or \"hole\" and a flat plane will \"slice it\" from the egg white quite neatly.  \n",
    "\n",
    "SVM's offer a variety of kernel functions to (Polynomial, Gaussian, Sigmoid, RBD, ...) to acommplish feats like this in multi-dimensional space.  The tricky part is finding the right one, and putting in the time to test & tune it.  Got a big data set, hope you have patientce. These kernels can be slow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What's so special about LD-SVMs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Locally-Deep Support Vector Machines (LD-SVMs)](https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/two-class-locally-deep-support-vector-machine) are essentially SVM's driven by [Local Deep Kernel Learning (LKDL)](http://manikvarma.org/code/LDKL/download.html), a kernel technique that addresses the projection needs descibed in the previous seciton, in a more efficent manner. LD-SVMs trade a bit of classification accuracy (usually less than a percentage point, occasionaly up to five) in favor of mulitple orders of magnitude peformance speedups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Choose, which one to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those who worship speed (or shiny new things in general) may be tempted to go all-in with LD-SVMs right of the bat, but a few preliminary considerations can guide you to a wiser choice.\n",
    "\n",
    "**Do you have infrastructure constraints?** If you want to get started with readymade LD-SVMs, Azure ML Stodio is pretty much the only game in town (as of May 2018). You'll have a hard time finding R packages or Python libaries to help you, though you might be able to build a wrapper over [Varma et. all's LKDL Kerel implemented in C++](http://manikvarma.org/code/LDKL/LDKL.zip). Even if you have complete freedom with respect to choice of language, you may still have Cloud vs. On-Premesis constraints. Understand your client, data sets, and terms of data use before building pipelines you're not allowed to use. Keep up with cloud security data proteciton capabilities (multiple providers provide government-level proteciton), or look into [how to run the Azure stack On-Premises](https://azure.microsoft.com/en-us/resources/videos/microsoft-azure-stack-azure-services-on-premises/) \n",
    "\n",
    "**How big is your data?** LD-SVM sings when up against tens or even hundreds of thousands observaations with tens or hundreds of dimensions. \n",
    "\n",
    "**Can you tolerate a loss of accuracy?** LD-SVM will usually cost you some accuracy in favor of speed. [the characteristics of your data [Jain et al fig. 2](http://manikvarma.org/code/LDKL/download.html) as well as your tuning pareamters can have en effeect. If every once of accruacy counts, consider staying with conventional SVM.\n",
    "\n",
    "**Have you tried the easy way first?** Most clients appreciate partial progress now rather than a complete solution never. Unless your data is aboslutely massive, you can probably try a few standard kernel functions with conventional SVM, in the language and on the infrastructure of your choice, to see where you stand. Step up to LD-SVM if conventional SVM fails you.\n",
    "\n",
    "Finallly, [keep an eye on the forums](https://social.msdn.microsoft.com/Forums/azure/en-US/b809782e-2169-4aa0-b512-18e6542e6600/when-would-you-use-two-class-locally-deep-svm-vs-normal-svm?forum=MachineLearning) to see if the situation changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "**Use the veh-prime dataset to classify cars vs. non-cars with SVMs.  Try 10 fold cross-validation, tune parameters and observe results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=7, repr.plot.height=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data, have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>f0</th><th scope=col>f1</th><th scope=col>f2</th><th scope=col>f3</th><th scope=col>f4</th><th scope=col>f5</th><th scope=col>f6</th><th scope=col>f7</th><th scope=col>f8</th><th scope=col>f9</th><th scope=col>⋯</th><th scope=col>f27</th><th scope=col>f28</th><th scope=col>f29</th><th scope=col>f30</th><th scope=col>f31</th><th scope=col>f32</th><th scope=col>f33</th><th scope=col>f34</th><th scope=col>f35</th><th scope=col>CLASS</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 0.063</td><td> 0.160</td><td> 0.509</td><td>-0.967</td><td>0.058 </td><td> 0.000</td><td> 0.874</td><td> 0.271</td><td> 1.307</td><td>-0.011</td><td>⋯     </td><td>-0.924</td><td>-0.077</td><td>0.108 </td><td>-0.003</td><td> 0.381</td><td>-0.314</td><td> 0.929</td><td>0.184 </td><td>-0.001</td><td>noncar</td></tr>\n",
       "\t<tr><td>-0.037</td><td>-0.325</td><td>-0.626</td><td>-0.029</td><td>0.121 </td><td>-0.409</td><td>-0.002</td><td>-0.835</td><td>-0.595</td><td>-0.253</td><td>⋯     </td><td> 0.270</td><td> 0.533</td><td>0.152 </td><td>-0.978</td><td> 0.157</td><td> 0.011</td><td>-0.254</td><td>0.453 </td><td>-0.621</td><td>noncar</td></tr>\n",
       "\t<tr><td> 0.000</td><td> 1.253</td><td> 0.833</td><td>-0.970</td><td>1.516 </td><td> 0.014</td><td>-0.378</td><td> 1.197</td><td> 0.546</td><td>-0.402</td><td>⋯     </td><td>-0.408</td><td> 1.550</td><td>0.010 </td><td>-0.652</td><td>-0.403</td><td>-0.151</td><td> 0.000</td><td>0.049 </td><td>-0.113</td><td>car   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllll}\n",
       " f0 & f1 & f2 & f3 & f4 & f5 & f6 & f7 & f8 & f9 & ⋯ & f27 & f28 & f29 & f30 & f31 & f32 & f33 & f34 & f35 & CLASS\\\\\n",
       "\\hline\n",
       "\t  0.063 &  0.160 &  0.509 & -0.967 & 0.058  &  0.000 &  0.874 &  0.271 &  1.307 & -0.011 & ⋯      & -0.924 & -0.077 & 0.108  & -0.003 &  0.381 & -0.314 &  0.929 & 0.184  & -0.001 & noncar\\\\\n",
       "\t -0.037 & -0.325 & -0.626 & -0.029 & 0.121  & -0.409 & -0.002 & -0.835 & -0.595 & -0.253 & ⋯      &  0.270 &  0.533 & 0.152  & -0.978 &  0.157 &  0.011 & -0.254 & 0.453  & -0.621 & noncar\\\\\n",
       "\t  0.000 &  1.253 &  0.833 & -0.970 & 1.516  &  0.014 & -0.378 &  1.197 &  0.546 & -0.402 & ⋯      & -0.408 &  1.550 & 0.010  & -0.652 & -0.403 & -0.151 &  0.000 & 0.049  & -0.113 & car   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "f0 | f1 | f2 | f3 | f4 | f5 | f6 | f7 | f8 | f9 | ⋯ | f27 | f28 | f29 | f30 | f31 | f32 | f33 | f34 | f35 | CLASS | \n",
       "|---|---|---|\n",
       "|  0.063 |  0.160 |  0.509 | -0.967 | 0.058  |  0.000 |  0.874 |  0.271 |  1.307 | -0.011 | ⋯      | -0.924 | -0.077 | 0.108  | -0.003 |  0.381 | -0.314 |  0.929 | 0.184  | -0.001 | noncar | \n",
       "| -0.037 | -0.325 | -0.626 | -0.029 | 0.121  | -0.409 | -0.002 | -0.835 | -0.595 | -0.253 | ⋯      |  0.270 |  0.533 | 0.152  | -0.978 |  0.157 |  0.011 | -0.254 | 0.453  | -0.621 | noncar | \n",
       "|  0.000 |  1.253 |  0.833 | -0.970 | 1.516  |  0.014 | -0.378 |  1.197 |  0.546 | -0.402 | ⋯      | -0.408 |  1.550 | 0.010  | -0.652 | -0.403 | -0.151 |  0.000 | 0.049  | -0.113 | car    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  f0     f1     f2     f3     f4    f5     f6     f7     f8     f9     ⋯ f27   \n",
       "1  0.063  0.160  0.509 -0.967 0.058  0.000  0.874  0.271  1.307 -0.011 ⋯ -0.924\n",
       "2 -0.037 -0.325 -0.626 -0.029 0.121 -0.409 -0.002 -0.835 -0.595 -0.253 ⋯  0.270\n",
       "3  0.000  1.253  0.833 -0.970 1.516  0.014 -0.378  1.197  0.546 -0.402 ⋯ -0.408\n",
       "  f28    f29   f30    f31    f32    f33    f34   f35    CLASS \n",
       "1 -0.077 0.108 -0.003  0.381 -0.314  0.929 0.184 -0.001 noncar\n",
       "2  0.533 0.152 -0.978  0.157  0.011 -0.254 0.453 -0.621 noncar\n",
       "3  1.550 0.010 -0.652 -0.403 -0.151  0.000 0.049 -0.113 car   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>846</li>\n",
       "\t<li>37</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 846\n",
       "\\item 37\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 846\n",
       "2. 37\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 846  37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mainDF = read.csv(\"veh-prime.csv\")\n",
    "head(mainDF, 3)\n",
    "dim(mainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "800-ish observations with 40-sh observations.\n",
    "\n",
    "### Check for NA's and overall value spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       f0                 f1                   f2            \n",
       " Min.   :-0.99900   Min.   :-2.5110000   Min.   :-1.9230000  \n",
       " 1st Qu.:-0.12075   1st Qu.:-0.8110000   1st Qu.:-0.7880000  \n",
       " Median : 0.00000   Median :-0.0820000   Median :-0.1400000  \n",
       " Mean   : 0.01666   Mean   : 0.0000154   Mean   :-0.0000437  \n",
       " 3rd Qu.: 0.15850   3rd Qu.: 0.7680000   3rd Qu.: 0.6710000  \n",
       " Max.   : 0.99700   Max.   : 3.0750000   Max.   : 2.2920000  \n",
       "       f3                  f4                   f5          \n",
       " Min.   :-0.992000   Min.   :-2.6690000   Min.   :-0.98700  \n",
       " 1st Qu.:-0.126750   1st Qu.:-0.7660000   1st Qu.:-0.13900  \n",
       " Median : 0.000000   Median :-0.1320000   Median : 0.00000  \n",
       " Mean   : 0.001991   Mean   : 0.0000674   Mean   :-0.01957  \n",
       " 3rd Qu.: 0.121000   3rd Qu.: 1.0090000   3rd Qu.: 0.08450  \n",
       " Max.   : 0.997000   Max.   : 1.8970000   Max.   : 0.99500  \n",
       "       f6                  f7                  f8                 f9           \n",
       " Min.   :-0.999000   Min.   :-1.940000   Min.   :-1.86300   Min.   :-0.995000  \n",
       " 1st Qu.:-0.143500   1st Qu.:-0.835000   1st Qu.:-0.59500   1st Qu.:-0.111750  \n",
       " Median : 0.000000   Median :-0.058000   Median :-0.08800   Median : 0.000000  \n",
       " Mean   :-0.003903   Mean   : 0.000019   Mean   :-0.00005   Mean   : 0.005255  \n",
       " 3rd Qu.: 0.133250   3rd Qu.: 0.779000   3rd Qu.: 0.41900   3rd Qu.: 0.132000  \n",
       " Max.   : 0.999000   Max.   : 4.901000   Max.   : 9.67300   Max.   : 0.999000  \n",
       "      f10                 f11                 f12           \n",
       " Min.   :-1.427000   Min.   :-0.995000   Min.   :-0.986000  \n",
       " 1st Qu.:-0.341000   1st Qu.:-0.120750   1st Qu.:-0.121000  \n",
       " Median :-0.123000   Median : 0.000000   Median : 0.000000  \n",
       " Mean   :-0.000039   Mean   : 0.004522   Mean   :-0.005171  \n",
       " 3rd Qu.: 0.311000   3rd Qu.: 0.154000   3rd Qu.: 0.131750  \n",
       " Max.   :10.091000   Max.   : 1.000000   Max.   : 0.994000  \n",
       "      f13                  f14                  f15          \n",
       " Min.   :-1.7100000   Min.   :-1.9120000   Min.   :-0.99900  \n",
       " 1st Qu.:-0.6795000   1st Qu.:-1.0160000   1st Qu.:-0.11050  \n",
       " Median :-0.3560000   Median : 0.2650000   Median : 0.00000  \n",
       " Mean   :-0.0000296   Mean   : 0.0000437   Mean   : 0.01061  \n",
       " 3rd Qu.: 0.8770000   3rd Qu.: 0.6490000   3rd Qu.: 0.17000  \n",
       " Max.   : 2.8920000   Max.   : 2.5690000   Max.   : 0.99800  \n",
       "      f16                 f17                f18           \n",
       " Min.   :-1.382000   Min.   :-0.99700   Min.   :-0.992000  \n",
       " 1st Qu.:-0.611000   1st Qu.:-0.13375   1st Qu.:-0.140000  \n",
       " Median :-0.225000   Median : 0.00000   Median : 0.000000  \n",
       " Mean   :-0.000073   Mean   : 0.01349   Mean   : 0.004541  \n",
       " 3rd Qu.: 0.933000   3rd Qu.: 0.16075   3rd Qu.: 0.103750  \n",
       " Max.   : 3.247000   Max.   : 0.98800   Max.   : 0.998000  \n",
       "      f19                  f20               f21               f22           \n",
       " Min.   :-2.0670000   Min.   :-1.8670   Min.   :-0.9960   Min.   :-1.448000  \n",
       " 1st Qu.:-0.7580000   1st Qu.:-0.6890   1st Qu.:-0.1303   1st Qu.:-0.688500  \n",
       " Median :-0.1380000   Median :-0.3225   Median : 0.0000   Median :-0.430000  \n",
       " Mean   : 0.0000024   Mean   : 0.0000   Mean   : 0.0127   Mean   : 0.000005  \n",
       " 3rd Qu.: 0.7580000   3rd Qu.: 0.9040   3rd Qu.: 0.1547   3rd Qu.: 0.832000  \n",
       " Max.   : 2.7560000   Max.   : 4.1850   Max.   : 0.9990   Max.   : 3.272000  \n",
       "      f23               f24                f25                  f26           \n",
       " Min.   :-0.9970   Min.   :-1.00000   Min.   :-2.0190000   Min.   :-1.798000  \n",
       " 1st Qu.:-0.1170   1st Qu.:-0.16550   1st Qu.:-0.7900000   1st Qu.:-0.730000  \n",
       " Median : 0.0000   Median : 0.00000   Median :-0.0520000   Median :-0.128500  \n",
       " Mean   : 0.0212   Mean   :-0.01544   Mean   : 0.0000083   Mean   :-0.000008  \n",
       " 3rd Qu.: 0.1718   3rd Qu.: 0.11625   3rd Qu.: 0.7160000   3rd Qu.: 0.339000  \n",
       " Max.   : 0.9910   Max.   : 0.99800   Max.   : 2.8670000   Max.   : 8.353000  \n",
       "      f27                 f28                 f29                 f30          \n",
       " Min.   :-0.997000   Min.   :-1.297000   Min.   :-0.965000   Min.   :-0.99500  \n",
       " 1st Qu.:-0.111750   1st Qu.:-0.890000   1st Qu.:-0.121250   1st Qu.:-0.10300  \n",
       " Median : 0.000000   Median :-0.077000   Median : 0.000000   Median : 0.00100  \n",
       " Mean   : 0.006547   Mean   :-0.000011   Mean   :-0.002281   Mean   : 0.02008  \n",
       " 3rd Qu.: 0.115000   3rd Qu.: 0.533000   3rd Qu.: 0.124250   3rd Qu.: 0.16300  \n",
       " Max.   : 0.999000   Max.   : 3.176000   Max.   : 0.995000   Max.   : 0.99400  \n",
       "      f31                 f32                 f33           \n",
       " Min.   :-1.411000   Min.   :-2.098000   Min.   :-0.993000  \n",
       " 1st Qu.:-0.851000   1st Qu.:-0.800000   1st Qu.:-0.131750  \n",
       " Median :-0.179000   Median :-0.151000   Median : 0.000000  \n",
       " Mean   :-0.000005   Mean   : 0.000026   Mean   : 0.005358  \n",
       " 3rd Qu.: 0.717000   3rd Qu.: 0.660000   3rd Qu.: 0.159500  \n",
       " Max.   : 3.180000   Max.   : 2.769000   Max.   : 0.981000  \n",
       "      f34                  f35              CLASS    \n",
       " Min.   :-1.9670000   Min.   :-0.99800   car   :429  \n",
       " 1st Qu.:-0.7235000   1st Qu.:-0.16075   noncar:417  \n",
       " Median : 0.1840000   Median : 0.00000               \n",
       " Mean   : 0.0000024   Mean   :-0.02619               \n",
       " 3rd Qu.: 0.7220000   3rd Qu.: 0.09125               \n",
       " Max.   : 2.0660000   Max.   : 0.99000               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(mainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything but the target variable is a numeric, no NaN's, most features range beteen +/- 1 (though not all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace string-based target variable with a numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       f0                 f1                   f2            \n",
       " Min.   :-0.99900   Min.   :-2.5110000   Min.   :-1.9230000  \n",
       " 1st Qu.:-0.12075   1st Qu.:-0.8110000   1st Qu.:-0.7880000  \n",
       " Median : 0.00000   Median :-0.0820000   Median :-0.1400000  \n",
       " Mean   : 0.01666   Mean   : 0.0000154   Mean   :-0.0000437  \n",
       " 3rd Qu.: 0.15850   3rd Qu.: 0.7680000   3rd Qu.: 0.6710000  \n",
       " Max.   : 0.99700   Max.   : 3.0750000   Max.   : 2.2920000  \n",
       "       f3                  f4                   f5          \n",
       " Min.   :-0.992000   Min.   :-2.6690000   Min.   :-0.98700  \n",
       " 1st Qu.:-0.126750   1st Qu.:-0.7660000   1st Qu.:-0.13900  \n",
       " Median : 0.000000   Median :-0.1320000   Median : 0.00000  \n",
       " Mean   : 0.001991   Mean   : 0.0000674   Mean   :-0.01957  \n",
       " 3rd Qu.: 0.121000   3rd Qu.: 1.0090000   3rd Qu.: 0.08450  \n",
       " Max.   : 0.997000   Max.   : 1.8970000   Max.   : 0.99500  \n",
       "       f6                  f7                  f8                 f9           \n",
       " Min.   :-0.999000   Min.   :-1.940000   Min.   :-1.86300   Min.   :-0.995000  \n",
       " 1st Qu.:-0.143500   1st Qu.:-0.835000   1st Qu.:-0.59500   1st Qu.:-0.111750  \n",
       " Median : 0.000000   Median :-0.058000   Median :-0.08800   Median : 0.000000  \n",
       " Mean   :-0.003903   Mean   : 0.000019   Mean   :-0.00005   Mean   : 0.005255  \n",
       " 3rd Qu.: 0.133250   3rd Qu.: 0.779000   3rd Qu.: 0.41900   3rd Qu.: 0.132000  \n",
       " Max.   : 0.999000   Max.   : 4.901000   Max.   : 9.67300   Max.   : 0.999000  \n",
       "      f10                 f11                 f12           \n",
       " Min.   :-1.427000   Min.   :-0.995000   Min.   :-0.986000  \n",
       " 1st Qu.:-0.341000   1st Qu.:-0.120750   1st Qu.:-0.121000  \n",
       " Median :-0.123000   Median : 0.000000   Median : 0.000000  \n",
       " Mean   :-0.000039   Mean   : 0.004522   Mean   :-0.005171  \n",
       " 3rd Qu.: 0.311000   3rd Qu.: 0.154000   3rd Qu.: 0.131750  \n",
       " Max.   :10.091000   Max.   : 1.000000   Max.   : 0.994000  \n",
       "      f13                  f14                  f15          \n",
       " Min.   :-1.7100000   Min.   :-1.9120000   Min.   :-0.99900  \n",
       " 1st Qu.:-0.6795000   1st Qu.:-1.0160000   1st Qu.:-0.11050  \n",
       " Median :-0.3560000   Median : 0.2650000   Median : 0.00000  \n",
       " Mean   :-0.0000296   Mean   : 0.0000437   Mean   : 0.01061  \n",
       " 3rd Qu.: 0.8770000   3rd Qu.: 0.6490000   3rd Qu.: 0.17000  \n",
       " Max.   : 2.8920000   Max.   : 2.5690000   Max.   : 0.99800  \n",
       "      f16                 f17                f18           \n",
       " Min.   :-1.382000   Min.   :-0.99700   Min.   :-0.992000  \n",
       " 1st Qu.:-0.611000   1st Qu.:-0.13375   1st Qu.:-0.140000  \n",
       " Median :-0.225000   Median : 0.00000   Median : 0.000000  \n",
       " Mean   :-0.000073   Mean   : 0.01349   Mean   : 0.004541  \n",
       " 3rd Qu.: 0.933000   3rd Qu.: 0.16075   3rd Qu.: 0.103750  \n",
       " Max.   : 3.247000   Max.   : 0.98800   Max.   : 0.998000  \n",
       "      f19                  f20               f21               f22           \n",
       " Min.   :-2.0670000   Min.   :-1.8670   Min.   :-0.9960   Min.   :-1.448000  \n",
       " 1st Qu.:-0.7580000   1st Qu.:-0.6890   1st Qu.:-0.1303   1st Qu.:-0.688500  \n",
       " Median :-0.1380000   Median :-0.3225   Median : 0.0000   Median :-0.430000  \n",
       " Mean   : 0.0000024   Mean   : 0.0000   Mean   : 0.0127   Mean   : 0.000005  \n",
       " 3rd Qu.: 0.7580000   3rd Qu.: 0.9040   3rd Qu.: 0.1547   3rd Qu.: 0.832000  \n",
       " Max.   : 2.7560000   Max.   : 4.1850   Max.   : 0.9990   Max.   : 3.272000  \n",
       "      f23               f24                f25                  f26           \n",
       " Min.   :-0.9970   Min.   :-1.00000   Min.   :-2.0190000   Min.   :-1.798000  \n",
       " 1st Qu.:-0.1170   1st Qu.:-0.16550   1st Qu.:-0.7900000   1st Qu.:-0.730000  \n",
       " Median : 0.0000   Median : 0.00000   Median :-0.0520000   Median :-0.128500  \n",
       " Mean   : 0.0212   Mean   :-0.01544   Mean   : 0.0000083   Mean   :-0.000008  \n",
       " 3rd Qu.: 0.1718   3rd Qu.: 0.11625   3rd Qu.: 0.7160000   3rd Qu.: 0.339000  \n",
       " Max.   : 0.9910   Max.   : 0.99800   Max.   : 2.8670000   Max.   : 8.353000  \n",
       "      f27                 f28                 f29                 f30          \n",
       " Min.   :-0.997000   Min.   :-1.297000   Min.   :-0.965000   Min.   :-0.99500  \n",
       " 1st Qu.:-0.111750   1st Qu.:-0.890000   1st Qu.:-0.121250   1st Qu.:-0.10300  \n",
       " Median : 0.000000   Median :-0.077000   Median : 0.000000   Median : 0.00100  \n",
       " Mean   : 0.006547   Mean   :-0.000011   Mean   :-0.002281   Mean   : 0.02008  \n",
       " 3rd Qu.: 0.115000   3rd Qu.: 0.533000   3rd Qu.: 0.124250   3rd Qu.: 0.16300  \n",
       " Max.   : 0.999000   Max.   : 3.176000   Max.   : 0.995000   Max.   : 0.99400  \n",
       "      f31                 f32                 f33           \n",
       " Min.   :-1.411000   Min.   :-2.098000   Min.   :-0.993000  \n",
       " 1st Qu.:-0.851000   1st Qu.:-0.800000   1st Qu.:-0.131750  \n",
       " Median :-0.179000   Median :-0.151000   Median : 0.000000  \n",
       " Mean   :-0.000005   Mean   : 0.000026   Mean   : 0.005358  \n",
       " 3rd Qu.: 0.717000   3rd Qu.: 0.660000   3rd Qu.: 0.159500  \n",
       " Max.   : 3.180000   Max.   : 2.769000   Max.   : 0.981000  \n",
       "      f34                  f35               TARGET        \n",
       " Min.   :-1.9670000   Min.   :-0.99800   Min.   :-1.00000  \n",
       " 1st Qu.:-0.7235000   1st Qu.:-0.16075   1st Qu.:-1.00000  \n",
       " Median : 0.1840000   Median : 0.00000   Median : 1.00000  \n",
       " Mean   : 0.0000024   Mean   :-0.02619   Mean   : 0.01418  \n",
       " 3rd Qu.: 0.7220000   3rd Qu.: 0.09125   3rd Qu.: 1.00000  \n",
       " Max.   : 2.0660000   Max.   : 0.99000   Max.   : 1.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mainDF$TARGET <- ifelse(mainDF$CLASS =='car',1,-1)\n",
    "mainDF$CLASS <- NULL\n",
    "summary(mainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Split into Test vs. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check frequency distribution of the target vaariable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "417"
      ],
      "text/latex": [
       "417"
      ],
      "text/markdown": [
       "417"
      ],
      "text/plain": [
       "[1] 417"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.50709219858156"
      ],
      "text/latex": [
       "0.50709219858156"
      ],
      "text/markdown": [
       "0.50709219858156"
      ],
      "text/plain": [
       "[1] 0.5070922"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(mainDF[mainDF$TARGET == -1,])\n",
    "nrow(mainDF[mainDF$TARGET == 1,])/nrow(mainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About a 50/50 split. Partition into test v. training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_obs = nrow(mainDF)\n",
    "\n",
    "set.seed(865309) \n",
    "\n",
    "index_shuffled <- sample(num_obs)\n",
    "training_ratio <- 0.66\n",
    "training_size <- round(num_obs * training_ratio)\n",
    "training_index <- index_shuffled[1:training_size]\n",
    "testing_index <- index_shuffled[(training_size+1):num_obs]\n",
    "trainset <- mainDF[training_index,]\n",
    "testset <- mainDF[testing_index,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.50709219858156"
      ],
      "text/latex": [
       "0.50709219858156"
      ],
      "text/markdown": [
       "0.50709219858156"
      ],
      "text/plain": [
       "[1] 0.5070922"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.507168458781362"
      ],
      "text/latex": [
       "0.507168458781362"
      ],
      "text/markdown": [
       "0.507168458781362"
      ],
      "text/plain": [
       "[1] 0.5071685"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.506944444444444"
      ],
      "text/latex": [
       "0.506944444444444"
      ],
      "text/markdown": [
       "0.506944444444444"
      ],
      "text/plain": [
       "[1] 0.5069444"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(mainDF[mainDF$TARGET == 1,])/nrow(mainDF)\n",
    "nrow(trainset[trainset$TARGET == 1,])/nrow(trainset)\n",
    "nrow(testset[testset$TARGET == 1,])/nrow(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got that 50/50 split for test & train; looking good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Two-Class Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: gplots\n",
      "\n",
      "Attaching package: ‘gplots’\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    lowess\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(e1071)\n",
    "library(ROCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>f0</th><th scope=col>f1</th><th scope=col>f2</th><th scope=col>f3</th><th scope=col>f4</th><th scope=col>f5</th><th scope=col>f6</th><th scope=col>f7</th><th scope=col>f8</th><th scope=col>f9</th><th scope=col>⋯</th><th scope=col>f27</th><th scope=col>f28</th><th scope=col>f29</th><th scope=col>f30</th><th scope=col>f31</th><th scope=col>f32</th><th scope=col>f33</th><th scope=col>f34</th><th scope=col>f35</th><th scope=col>TARGET</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>774</th><td>-0.023</td><td>-0.811</td><td>-0.464</td><td>-0.436</td><td>-0.766</td><td>-0.677</td><td>-0.091</td><td>-0.895</td><td>-0.342</td><td> 0.110</td><td>⋯     </td><td> 0.375</td><td>-0.077</td><td>-0.001</td><td>0.068 </td><td>-0.403</td><td>-0.638</td><td>-0.690</td><td>-1.026</td><td> 0.843</td><td>-1    </td></tr>\n",
       "\t<tr><th scope=row>694</th><td> 0.414</td><td>-0.447</td><td> 0.184</td><td>-0.432</td><td>-0.449</td><td> 0.209</td><td> 0.000</td><td>-1.074</td><td>-0.849</td><td> 0.011</td><td>⋯     </td><td> 0.020</td><td>-1.297</td><td> 0.118</td><td>0.107 </td><td> 0.381</td><td>-1.125</td><td> 0.500</td><td>-0.488</td><td> 0.154</td><td>-1    </td></tr>\n",
       "\t<tr><th scope=row>13</th><td> 0.655</td><td>-0.690</td><td> 0.184</td><td> 0.472</td><td>-0.513</td><td>-0.090</td><td>-0.646</td><td> 0.062</td><td> 0.799</td><td>-0.111</td><td>⋯     </td><td>-0.100</td><td>-0.280</td><td>-0.063</td><td>0.057 </td><td>-0.179</td><td> 0.011</td><td> 0.705</td><td>-0.085</td><td>-0.813</td><td>-1    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllll}\n",
       "  & f0 & f1 & f2 & f3 & f4 & f5 & f6 & f7 & f8 & f9 & ⋯ & f27 & f28 & f29 & f30 & f31 & f32 & f33 & f34 & f35 & TARGET\\\\\n",
       "\\hline\n",
       "\t774 & -0.023 & -0.811 & -0.464 & -0.436 & -0.766 & -0.677 & -0.091 & -0.895 & -0.342 &  0.110 & ⋯      &  0.375 & -0.077 & -0.001 & 0.068  & -0.403 & -0.638 & -0.690 & -1.026 &  0.843 & -1    \\\\\n",
       "\t694 &  0.414 & -0.447 &  0.184 & -0.432 & -0.449 &  0.209 &  0.000 & -1.074 & -0.849 &  0.011 & ⋯      &  0.020 & -1.297 &  0.118 & 0.107  &  0.381 & -1.125 &  0.500 & -0.488 &  0.154 & -1    \\\\\n",
       "\t13 &  0.655 & -0.690 &  0.184 &  0.472 & -0.513 & -0.090 & -0.646 &  0.062 &  0.799 & -0.111 & ⋯      & -0.100 & -0.280 & -0.063 & 0.057  & -0.179 &  0.011 &  0.705 & -0.085 & -0.813 & -1    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | f0 | f1 | f2 | f3 | f4 | f5 | f6 | f7 | f8 | f9 | ⋯ | f27 | f28 | f29 | f30 | f31 | f32 | f33 | f34 | f35 | TARGET | \n",
       "|---|---|---|\n",
       "| 774 | -0.023 | -0.811 | -0.464 | -0.436 | -0.766 | -0.677 | -0.091 | -0.895 | -0.342 |  0.110 | ⋯      |  0.375 | -0.077 | -0.001 | 0.068  | -0.403 | -0.638 | -0.690 | -1.026 |  0.843 | -1     | \n",
       "| 694 |  0.414 | -0.447 |  0.184 | -0.432 | -0.449 |  0.209 |  0.000 | -1.074 | -0.849 |  0.011 | ⋯      |  0.020 | -1.297 |  0.118 | 0.107  |  0.381 | -1.125 |  0.500 | -0.488 |  0.154 | -1     | \n",
       "| 13 |  0.655 | -0.690 |  0.184 |  0.472 | -0.513 | -0.090 | -0.646 |  0.062 |  0.799 | -0.111 | ⋯      | -0.100 | -0.280 | -0.063 | 0.057  | -0.179 |  0.011 |  0.705 | -0.085 | -0.813 | -1     | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    f0     f1     f2     f3     f4     f5     f6     f7     f8     f9     ⋯\n",
       "774 -0.023 -0.811 -0.464 -0.436 -0.766 -0.677 -0.091 -0.895 -0.342  0.110 ⋯\n",
       "694  0.414 -0.447  0.184 -0.432 -0.449  0.209  0.000 -1.074 -0.849  0.011 ⋯\n",
       "13   0.655 -0.690  0.184  0.472 -0.513 -0.090 -0.646  0.062  0.799 -0.111 ⋯\n",
       "    f27    f28    f29    f30   f31    f32    f33    f34    f35    TARGET\n",
       "774  0.375 -0.077 -0.001 0.068 -0.403 -0.638 -0.690 -1.026  0.843 -1    \n",
       "694  0.020 -1.297  0.118 0.107  0.381 -1.125  0.500 -0.488  0.154 -1    \n",
       "13  -0.100 -0.280 -0.063 0.057 -0.179  0.011  0.705 -0.085 -0.813 -1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(testset,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>f0</th><th scope=col>f1</th><th scope=col>f2</th><th scope=col>f3</th><th scope=col>f4</th><th scope=col>f5</th><th scope=col>f6</th><th scope=col>f7</th><th scope=col>f8</th><th scope=col>f9</th><th scope=col>⋯</th><th scope=col>f26</th><th scope=col>f27</th><th scope=col>f28</th><th scope=col>f29</th><th scope=col>f30</th><th scope=col>f31</th><th scope=col>f32</th><th scope=col>f33</th><th scope=col>f34</th><th scope=col>f35</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>774</th><td>-0.023</td><td>-0.811</td><td>-0.464</td><td>-0.436</td><td>-0.766</td><td>-0.677</td><td>-0.091</td><td>-0.895</td><td>-0.342</td><td> 0.110</td><td>⋯     </td><td> 0.740</td><td> 0.375</td><td>-0.077</td><td>-0.001</td><td>0.068 </td><td>-0.403</td><td>-0.638</td><td>-0.690</td><td>-1.026</td><td> 0.843</td></tr>\n",
       "\t<tr><th scope=row>694</th><td> 0.414</td><td>-0.447</td><td> 0.184</td><td>-0.432</td><td>-0.449</td><td> 0.209</td><td> 0.000</td><td>-1.074</td><td>-0.849</td><td> 0.011</td><td>⋯     </td><td> 0.606</td><td> 0.020</td><td>-1.297</td><td> 0.118</td><td>0.107 </td><td> 0.381</td><td>-1.125</td><td> 0.500</td><td>-0.488</td><td> 0.154</td></tr>\n",
       "\t<tr><th scope=row>13</th><td> 0.655</td><td>-0.690</td><td> 0.184</td><td> 0.472</td><td>-0.513</td><td>-0.090</td><td>-0.646</td><td> 0.062</td><td> 0.799</td><td>-0.111</td><td>⋯     </td><td>-0.195</td><td>-0.100</td><td>-0.280</td><td>-0.063</td><td>0.057 </td><td>-0.179</td><td> 0.011</td><td> 0.705</td><td>-0.085</td><td>-0.813</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllllllllllllllllllllllll}\n",
       "  & f0 & f1 & f2 & f3 & f4 & f5 & f6 & f7 & f8 & f9 & ⋯ & f26 & f27 & f28 & f29 & f30 & f31 & f32 & f33 & f34 & f35\\\\\n",
       "\\hline\n",
       "\t774 & -0.023 & -0.811 & -0.464 & -0.436 & -0.766 & -0.677 & -0.091 & -0.895 & -0.342 &  0.110 & ⋯      &  0.740 &  0.375 & -0.077 & -0.001 & 0.068  & -0.403 & -0.638 & -0.690 & -1.026 &  0.843\\\\\n",
       "\t694 &  0.414 & -0.447 &  0.184 & -0.432 & -0.449 &  0.209 &  0.000 & -1.074 & -0.849 &  0.011 & ⋯      &  0.606 &  0.020 & -1.297 &  0.118 & 0.107  &  0.381 & -1.125 &  0.500 & -0.488 &  0.154\\\\\n",
       "\t13 &  0.655 & -0.690 &  0.184 &  0.472 & -0.513 & -0.090 & -0.646 &  0.062 &  0.799 & -0.111 & ⋯      & -0.195 & -0.100 & -0.280 & -0.063 & 0.057  & -0.179 &  0.011 &  0.705 & -0.085 & -0.813\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | f0 | f1 | f2 | f3 | f4 | f5 | f6 | f7 | f8 | f9 | ⋯ | f26 | f27 | f28 | f29 | f30 | f31 | f32 | f33 | f34 | f35 | \n",
       "|---|---|---|\n",
       "| 774 | -0.023 | -0.811 | -0.464 | -0.436 | -0.766 | -0.677 | -0.091 | -0.895 | -0.342 |  0.110 | ⋯      |  0.740 |  0.375 | -0.077 | -0.001 | 0.068  | -0.403 | -0.638 | -0.690 | -1.026 |  0.843 | \n",
       "| 694 |  0.414 | -0.447 |  0.184 | -0.432 | -0.449 |  0.209 |  0.000 | -1.074 | -0.849 |  0.011 | ⋯      |  0.606 |  0.020 | -1.297 |  0.118 | 0.107  |  0.381 | -1.125 |  0.500 | -0.488 |  0.154 | \n",
       "| 13 |  0.655 | -0.690 |  0.184 |  0.472 | -0.513 | -0.090 | -0.646 |  0.062 |  0.799 | -0.111 | ⋯      | -0.195 | -0.100 | -0.280 | -0.063 | 0.057  | -0.179 |  0.011 |  0.705 | -0.085 | -0.813 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    f0     f1     f2     f3     f4     f5     f6     f7     f8     f9     ⋯\n",
       "774 -0.023 -0.811 -0.464 -0.436 -0.766 -0.677 -0.091 -0.895 -0.342  0.110 ⋯\n",
       "694  0.414 -0.447  0.184 -0.432 -0.449  0.209  0.000 -1.074 -0.849  0.011 ⋯\n",
       "13   0.655 -0.690  0.184  0.472 -0.513 -0.090 -0.646  0.062  0.799 -0.111 ⋯\n",
       "    f26    f27    f28    f29    f30   f31    f32    f33    f34    f35   \n",
       "774  0.740  0.375 -0.077 -0.001 0.068 -0.403 -0.638 -0.690 -1.026  0.843\n",
       "694  0.606  0.020 -1.297  0.118 0.107  0.381 -1.125  0.500 -0.488  0.154\n",
       "13  -0.195 -0.100 -0.280 -0.063 0.057 -0.179  0.011  0.705 -0.085 -0.813"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(testset[-37],3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First SVM: Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"AUC=0.968743970673355\"\n"
     ]
    }
   ],
   "source": [
    "# Linear kernel\n",
    "svm.model <- svm(TARGET ~ ., data = trainset, cost = 1, kernel='linear') \n",
    "svm.pred <- predict(svm.model, testset[,-37])\n",
    "\n",
    "pred <- prediction(svm.pred, testset$TARGET)\n",
    "auc <- performance(pred, \"auc\")\n",
    "print(paste(\"AUC=\", auc@y.values[[1]], sep=\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple linear model yields AUC of 0.9687.  Not too bad.  Time to start keeping score.\n",
    "\n",
    "|SVM Kernel|Tuning|AUC              |\n",
    "|----------|------|-----------------|\n",
    "|linear    |cost=1|0.968743970673355|\n",
    "\n",
    "And create a function so we can test more quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_svm_all_defaults <- function(trainDF, testDF, theKernel,  theDegree = 3, \n",
    "                                  theGamma = -1, theCoef0 = 0, theCost = 1,\n",
    "                                  theEpsilon = 0.1, printSummary = FALSE) {\n",
    "    if (theGamma == -1){    \n",
    "        if (theKernel == 'RBF'){\n",
    "           svm.model <- svm(TARGET ~ ., data = trainDF, \n",
    "                            degree = theDegree, coef0 = theCoef0,cost = theCost, \n",
    "                            epsilon = theEpsilon)          \n",
    "        } else {\n",
    "           svm.model <- svm(TARGET ~ ., data = trainDF, kernel=theKernel, \n",
    "                            degree = theDegree, coef0 = theCoef0,cost = theCost,\n",
    "                            epsilon = theEpsilon)         \n",
    "        }\n",
    "    } else {\n",
    "        if (theKernel == 'RBF'){\n",
    "           svm.model <- svm(TARGET ~ ., data = trainDF, \n",
    "                            degree = theDegree, coef0 = theCoef0,cost = theCost, \n",
    "                            epsilon = theEpsilon, gamma = theGamma)          \n",
    "        } else {\n",
    "           svm.model <- svm(TARGET ~ ., data = trainDF, kernel=theKernel, \n",
    "                            degree = theDegree, coef0 = theCoef0,cost = theCost,\n",
    "                            epsilon = theEpsilon, gamma = theGamma)         \n",
    "        }        \n",
    "    }\n",
    "\n",
    "\n",
    "    if (printSummary){\n",
    "        print(summary (svm.model))\n",
    "    }\n",
    "    \n",
    "    svm.pred <- predict(svm.model, testDF[,-37])\n",
    "\n",
    "    pred <- prediction(svm.pred, testDF$TARGET)\n",
    "    auc <- performance(pred, \"auc\")\n",
    "    print(paste(\"AUC=\", auc@y.values[[1]], sep=\"\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try a bunch of svm models, all with defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"AUC=0.968743970673355\"\n",
      "[1] \"AUC=0.885828670654063\"\n",
      "[1] \"AUC=0.977570904881343\"\n",
      "[1] \"AUC=0.809039166505885\"\n"
     ]
    }
   ],
   "source": [
    "test_svm_all_defaults(trainset, testset, 'linear')\n",
    "test_svm_all_defaults(trainset, testset, 'polynomial')\n",
    "test_svm_all_defaults(trainset, testset, 'RBF')\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|SVM Kernel|AUC              |\n",
    "|----------|-----------------|\n",
    "|linear    |0.968743970673355|\n",
    "|polynomial|0.885828670654063|\n",
    "|RBF       |0.977570904881343|\n",
    "|sigmoid   |0.809039166505885|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so RBF the default kernel, with default parameters, yeilds 0.9776 AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Try some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "svm(formula = TARGET ~ ., data = trainDF, kernel = theKernel, degree = theDegree, \n",
      "    coef0 = theCoef0, cost = theCost)\n",
      "\n",
      "\n",
      "Parameters:\n",
      "   SVM-Type:  eps-regression \n",
      " SVM-Kernel:  linear \n",
      "       cost:  1 \n",
      "      gamma:  0.02777778 \n",
      "    epsilon:  0.1 \n",
      "\n",
      "\n",
      "Number of Support Vectors:  471\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[1] \"AUC=0.968743970673355\"\n"
     ]
    }
   ],
   "source": [
    "test_svm_all_defaults(trainset, testset, 'linear', printSummary=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Parameter tuning of ‘svm’:\n",
       "\n",
       "- sampling method: 10-fold cross validation \n",
       "\n",
       "- best parameters:\n",
       " cost\n",
       "  100\n",
       "\n",
       "- best performance: 0.3881963 \n",
       "\n",
       "- Detailed performance results:\n",
       "   cost     error dispersion\n",
       "1 1e-03 0.8568592 0.14758215\n",
       "2 1e-02 0.6229603 0.07652119\n",
       "3 1e-01 0.4392814 0.18625185\n",
       "4 1e+00 0.4004802 0.21269152\n",
       "5 5e+00 0.3920089 0.19928967\n",
       "6 1e+01 0.3887190 0.19181545\n",
       "7 1e+02 0.3881963 0.18289181\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "best.tune(method = svm, train.x = TARGET ~ ., data = trainset, ranges = list(cost = c(0.001, \n",
       "    0.01, 0.1, 1, 5, 10, 100)), kernel = \"linear\")\n",
       "\n",
       "\n",
       "Parameters:\n",
       "   SVM-Type:  eps-regression \n",
       " SVM-Kernel:  linear \n",
       "       cost:  100 \n",
       "      gamma:  0.02777778 \n",
       "    epsilon:  0.1 \n",
       "\n",
       "\n",
       "Number of Support Vectors:  481\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tune.out<-tune(svm ,TARGET ~ ., data = trainset,  ,kernel =\"linear\",\n",
    "        ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ))\n",
    "summary(tune.out)\n",
    "\n",
    "# get the best model\n",
    "bestmod <-tune.out$best.model\n",
    "summary (bestmod )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"AUC=0.968743970673355\"\n",
      "[1] \"AUC=0.9704321821339\"\n"
     ]
    }
   ],
   "source": [
    "test_svm_all_defaults(trainset, testset, 'linear')\n",
    "test_svm_all_defaults(trainset, testset, 'linear', theGamma = 0.02777778, theCost = 100, theEpsilon = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_svm_all_defaults(trainset, testset, 'linear')\n",
    "test_svm_all_defaults(trainset, testset, 'linear')\n",
    "test_svm_all_defaults(trainset, testset, 'linear')\n",
    "test_svm_all_defaults(trainset, testset, 'linear')\n",
    "test_svm_all_defaults(trainset, testset, 'linear')\n",
    "test_svm_all_defaults(trainset, testset, 'linear')\n",
    "test_svm_all_defaults(trainset, testset, 'linear')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Play with Polynomial parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"AUC=0.5\"\n",
      "[1] \"AUC=0.925670461122902\"\n",
      "[1] \"AUC=0.854427937487942\"\n",
      "[1] \"AUC=0.885828670654063\"\n",
      "[1] \"AUC=0.842272814972025\"\n",
      "[1] \"AUC=0.811595601003279\"\n"
     ]
    }
   ],
   "source": [
    "test_svm_all_defaults(trainset, testset, 'polynomial', theDegree = 0)\n",
    "test_svm_all_defaults(trainset, testset, 'polynomial', theDegree = 1)\n",
    "test_svm_all_defaults(trainset, testset, 'polynomial', theDegree = 2)\n",
    "test_svm_all_defaults(trainset, testset, 'polynomial', theDegree = 3)\n",
    "test_svm_all_defaults(trainset, testset, 'polynomial', theDegree = 4)\n",
    "test_svm_all_defaults(trainset, testset, 'polynomial', theDegree = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No big surpise that theDegree of 0 yiels 0.5; and 1 gives the same results as linear.  What's interesting, is that as you increase the degre, AUC degrades.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"AUC=0.983600231526144\"\n",
      "[1] \"AUC=0.986204900636697\"\n",
      "[1] \"AUC=0.98519197376037\"\n",
      "[1] \"AUC=0.983214354620876\"\n",
      "[1] \"AUC=0.981912020065599\"\n"
     ]
    }
   ],
   "source": [
    "test_svm_all_defaults(trainset, testset, 'polynomial', theCoef0 = 1, theDegree = 3)\n",
    "test_svm_all_defaults(trainset, testset, 'polynomial', theCoef0 = 2, theDegree = 3)\n",
    "test_svm_all_defaults(trainset, testset, 'polynomial', theCoef0 = 3, theDegree = 3)\n",
    "test_svm_all_defaults(trainset, testset, 'polynomial', theCoef0 = 4, theDegree = 3)\n",
    "test_svm_all_defaults(trainset, testset, 'polynomial', theCoef0 = 5,theDegree = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_svm_all_defaults(trainset, testset, 'RBF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"AUC=0.809039166505885\"\n",
      "[1] \"AUC=0.642581516496238\"\n",
      "[1] \"AUC=0.5990256608142\"\n",
      "[1] \"AUC=0.7433918579973\"\n",
      "[1] \"AUC=0.744645957939418\"\n",
      "[1] \"AUC=0.744645957939418\"\n"
     ]
    }
   ],
   "source": [
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 0)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 1)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 2)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 3)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 4)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"AUC=0.809039166505885\"\n",
      "[1] \"AUC=0.75694578429481\"\n",
      "[1] \"AUC=0.650829635346324\"\n",
      "[1] \"AUC=0.664624734709628\"\n",
      "[1] \"AUC=0.657486011962185\"\n",
      "[1] \"AUC=0.640893305035694\"\n"
     ]
    }
   ],
   "source": [
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 0)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 0.1)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 0.2)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 0.3)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 0.4)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"AUC=0.809039166505885\"\n",
      "[1] \"AUC=0.75694578429481\"\n",
      "[1] \"AUC=0.809714451090103\"\n",
      "[1] \"AUC=0.80918387034536\"\n",
      "[1] \"AUC=0.814779085471735\"\n",
      "[1] \"AUC=0.750868223036852\"\n"
     ]
    }
   ],
   "source": [
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 0)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 0.1)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 0.01)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 0.001)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 0.0001)\n",
    "test_svm_all_defaults(trainset, testset, 'sigmoid', theCoef0 = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Try 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try an SVM with Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"AUC=0.933822110746672\"\n"
     ]
    }
   ],
   "source": [
    "gamma = .1\n",
    "kernel = 'sigmoid'\n",
    "svm.model <- svm(TARGET ~ ., data = trainset, cost = 1, gamma = gamma)#, kernel=kernel) \n",
    "svm.pred <- predict(svm.model, testset[,-37])\n",
    "\n",
    "pred <- prediction(svm.pred, testset$TARGET)\n",
    "auc <- performance(pred, \"auc\")\n",
    "print(paste(\"AUC=\", auc@y.values[[1]], sep=\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|SVM Kernel|Tuning                                            |AUC              |\n",
    "|----------|--------------------------------------------------|-----------------|\n",
    "|linear    |cost=1 (defualt)                                  |0.968743970673355|\n",
    "|sigmoid   |cost=1 (defualt); gamma = 0.1                     |0.933822110746672|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to the Question(s) at Hand\n",
    "**Use the veh-prime dataset to classify cars vs. non-cars with SVMs.  Try 10 fold cross-validation, tune parameters and observe results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using package e1071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/home/vagrant/R/x86_64-pc-linux-gnu-library/3.2’\n",
      "(as ‘lib’ is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded source packages are in\n",
      "\t‘/tmp/Rtmp566l6i/downloaded_packages’\n"
     ]
    }
   ],
   "source": [
    "#install the package\n",
    "install.packages(\"e1071\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the library\n",
    "# Note that e1071 contains other classification and clustering methods and is a useful library to keep in your toolbox.\n",
    "library(e1071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'autosdf' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'autosdf' not found\nTraceback:\n",
      "1. svm(TARGET ~ ., data = autosdf, kernel = \"linear\", cost = 10, \n .     scale = FALSE)",
      "2. svm.formula(TARGET ~ ., data = autosdf, kernel = \"linear\", cost = 10, \n .     scale = FALSE)",
      "3. identical(class(eval.parent(m$data)), \"matrix\")",
      "4. eval.parent(m$data)",
      "5. eval(expr, p)",
      "6. eval(expr, envir, enclos)"
     ]
    }
   ],
   "source": [
    "# svm i sused to train a support vector machine\n",
    "# Various arguments are interesting - In this case you will see that we are using a linear kernel\n",
    "# You can also explore other kerney and observe how the decision boundary changes.\n",
    "# Various kernels are available - linear, polynomial, radial basis, and sigmoid.\n",
    "\n",
    "\n",
    "# You will also notice that we are using a cost = 10. \n",
    "# Cost refers to the C constant of the regularization term in a Lagrang formulae\n",
    "svmfit<-svm(TARGET~., data=autosdf, kernel=\"linear\", cost=10, scale=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the decision boundary\n",
    "# plot(svmfit , autosdf)\n",
    "svmfit$index\n",
    "summary (svmfit )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try using a smaller cost value and see how it impacts the decision boundary\n",
    "svmfit<-svm(TARGET~., data=autosdf, kernel=\"linear\", cost=0.1, scale=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot(svmfit , autosdf)\n",
    "svmfit$index\n",
    "summary (svmfit )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Two-Class LocallyDeep Support Vector Machine (MSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
