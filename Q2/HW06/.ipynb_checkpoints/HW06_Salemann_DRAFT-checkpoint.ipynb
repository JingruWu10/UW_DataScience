{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVEN MORE CAR TALK: BAYESIAN PRICING\n",
    "**_The search for normality and significance_**\n",
    "### Data Science 410 BB\n",
    "#### University of Washington Professional & Continuing Education\n",
    "#### Homework 6: Applying Bayesian modeling to auto price data\n",
    "#### Leo Salemann, 2/14/18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data, Setup some Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read.auto = function(file = '../../../DataScience410/Lecture1/Automobile price data _Raw_.csv'){\n",
    "  ## Read the csv file\n",
    "  autos <- read.csv(file, header = TRUE, \n",
    "                      stringsAsFactors = FALSE)\n",
    "\n",
    "  ## Coerce some character columns to numeric\n",
    "  numcols <- c('price', 'bore', 'stroke', 'horsepower', 'peak.rpm')\n",
    "  autos[, numcols] <- lapply(autos[, numcols], as.numeric)\n",
    "\n",
    "  ## Remove cases or rows with missing values. In this case we keep the \n",
    "  ## rows which do not have nas. \n",
    "  autos[complete.cases(autos), ]\n",
    "}\n",
    "autos = read.auto()\n",
    "\n",
    "head(autos, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos$logPrice = log(autos$price)\n",
    "head(autos, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posterior = function(prior, like){\n",
    "    post = prior * like  # Compute the product of the probabilities\n",
    "    post / sum(post) # Normalize and return\n",
    "}\n",
    "\n",
    "plot.post = function(prior, like, post, x){\n",
    "    maxy = max(c(prior, like, post))\n",
    "    plot(x, like, , lty = 1, ylim = c(0.0, maxy), \n",
    "         ylab = 'Density', xlab = 'Parameter value',\n",
    "         main = 'Density of prior, likelihood, posterior',\n",
    "         lwd = 2, col = 'green')\n",
    "    lines(x, prior, lty = 2, lwd = 2, col = 'blue')    \n",
    "    lines(x, post, lty = 1, lwd = 2, col = 'red')\n",
    "    legend('topright', c('likelihood', 'prior', 'posterior'), \n",
    "    lty=1, col=c('green', 'blue', 'red'), bty='n', cex=1.0)\n",
    "    \n",
    "    cat(' Maximum of prior density =', round(x[which.max(prior)], 3), '\\n',\n",
    "        'Maximum likelihood =', round(x[which.max(like)], 3), '\\n',\n",
    "         'MAP =', round(x[which.max(post)], 3))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nSamps = 100000\n",
    "qs = c(0.025, 0.975)\n",
    "\n",
    "plot.ci = function(p, post, nSamps, qs){\n",
    "    ## This function computes a credible interval using an assumption\n",
    "    ## of symetry in the bulk of the distribution to keep the \n",
    "    ## calculation simple. \n",
    "    ## Compute a large sample by resampling with replacement\n",
    "    samps = sample(p, size = nSamps, replace = TRUE, prob = post)\n",
    "    ci = quantile(samps, probs = qs) # compute the quantiles\n",
    "    \n",
    "    ## Plot the density with the credible interval\n",
    "    interval = qs[2] - qs[1]\n",
    "    title = paste('Posterior density with', interval, 'credible interval')\n",
    "    plot(p, post, , typ = 'l', ylab = 'Density', xlab = 'Parameter value',\n",
    "         main = title, lwd = 2, col = 'blue')\n",
    "    abline(v = ci[1], col = 'red', lty = 2, lwd = 2)\n",
    "    abline(v = ci[2], col = 'red', lty = 2, lwd = 2)\n",
    "    cat('The', interval, 'Credible interval is', \n",
    "        round(ci[1], 2), 'to', round(ci[2], 2))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp.like = function(p, x){\n",
    "    l = rep(0, length = length(p))\n",
    "    sigmaSqr = sd(x)^2\n",
    "    xBar = mean(x)\n",
    "    cat(' Mean =', xBar, 'Standard deviation =', sqrt(sigmaSqr), '\\n')\n",
    "    n = length(x)\n",
    "    l = sapply(p, function(u) exp(- n* (xBar - u)^2 / (2 * sigmaSqr)))\n",
    "    l / sum(l) # Normalize and return\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Estimate, Stratified by Aspiration\n",
    "Compare the difference of the Bayesian estimate of the mean of log of auto price stratified by 1) aspiration and 2) fuel type. Use both numerical and graphical methods for your comparison. \n",
    "\n",
    "- Are these means different within a 95% credible interval? \n",
    "- How do your conclusions compare to the results you obtained using the to the bootstrap resampled distribution of the mean and the t-test on the log price?   \n",
    "- Use a Normal(mean(sample), sigma(sample)) as your prior distribution for both exercises. \n",
    "- Use sigma(sample), the empirical value of the standard deviation, as a fixed parameter in your likelihood for both exercises. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos.std = autos[autos$aspiration == 'std',]\n",
    "autos.turbo = autos[autos$aspiration == 'turbo',]\n",
    "\n",
    "head(autos.std, 3)\n",
    "head(autos.turbo, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000 \n",
    "p = seq(9.1, 9.9, length = N) \n",
    "\n",
    "meanLogPrice.std = mean(autos.std$logPrice)\n",
    "sdevLogPrice.std = sd(autos.std$logPrice)\n",
    "\n",
    "autos.std$logPrice = sort(autos.std$logPrice, decreasing = FALSE)\n",
    "\n",
    "pp = dnorm(p, mean = meanLogPrice, sd = sdevLogPrice.std) \n",
    "pp = pp / sum(pp)\n",
    "\n",
    "like.autos.std = comp.like(p, autos.std$logPrice)\n",
    "post.autos.std = posterior(pp, like.autos.std)\n",
    "plot.post(pp, like.autos.std, post.autos.std, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 1000 \n",
    "# p = seq(9.2, 9.8, length = N) \n",
    "\n",
    "meanLogPrice.turbo = mean(c(autos.turbo$logPrice))\n",
    "sdevLogPrice.turbo = sd(autos.turbo$logPrice)\n",
    "autos.turbo$logPrice = sort(autos.turbo$logPrice, decreasing = FALSE)\n",
    "\n",
    "pp = dnorm(p, mean = meanLogPrice.turbo, sd = sdevLogPrice.turbo) ## start with a fairly broad prior\n",
    "pp = pp / sum(pp)\n",
    "\n",
    "like.autos.turbo = comp.like(p, autos.turbo$logPrice)\n",
    "post.autos.turbo = posterior(pp, like.autos.turbo)\n",
    "plot.post(pp, like.autos.turbo, post.autos.turbo, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSamps = 100000\n",
    "qs = c(0.025, 0.975)\n",
    "plot.ci(p, post.autos.std, nSamps, qs)\n",
    "plot.ci(p, post.autos.turbo, nSamps, qs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions, Aspiration\n",
    "- Credible intervals match confidence intervals very closely\n",
    "  - Standard: [9.209-9.368] confidence; [9.21-9.37] credible\n",
    "  - Turbo: [9.502-9.749] confidence; [9.5-9.75] credible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Estimate, Stratified by Fuel Type\n",
    "Compare the difference of the Bayesian estimate of the mean of log of auto price stratified by 1) aspiration and 2) fuel type. Use both numerical and graphical methods for your comparison. \n",
    "\n",
    "- Are these means different within a 95% credible interval? \n",
    "- How do your conclusions compare to the results you obtained using the to the bootstrap resampled distribution of the mean and the t-test on the log price?\n",
    "- Use a Normal(mean(sample), sigma(sample)) as your prior distribution for both exercises. \n",
    "- Use sigma(sample), the empirical value of the standard deviation, as a fixed parameter in your likelihood for both exercises.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos.gas = auto.price[auto.price$fuel.type == 'gas',]\n",
    "autos.diesel = auto.price[auto.price$fuel.type == 'diesel',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Estimate, Stratified by Body Style\n",
    "- Compare the differences of the Bayesian estimate of the distribution of the log price of the autos grouped by body style. You will need to do this pair wise; e.g. between each possible pairing of body styles. Use both numerical and graphical methods for your comparison. \n",
    "- Which pairs of means are different within a 95% credible interval? \n",
    "- How do your conclusions compare to the results you obtained from the bootstrap method, ANOVA and Tukeyâ€™s HSD analysis you previously performed? \n",
    "- Notice that the posterior is closer to the likelihood for groups with more data values. \n",
    "\n",
    "- Use a Normal(mean(sample), sigma(sample)) as your prior distribution for both exercises. Use sigma(sample), the empirical value of the standard deviation, as a fixed parameter in your likelihood for both exercises.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VVVVVVVVVVVV JUNK VVVVVVVVVV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
